{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "This notebook shows the latencies for queries run against a vector database on AstraDB that is prepopulated with data.\n",
    "\n",
    "In order to run this notebook, you will need a .env file that looks like this:\n",
    "\n",
    "```\n",
    "ARIZE_SPACE_ID=\"...==\"\n",
    "ARIZE_API_KEY=\"...\"\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN=\"AstraCS:...\"\n",
    "ASTRA_DB_API_ENDPOINT=\"https://....apps.astra.datastax.com\"\n",
    "ASTRA_DB_ID=\"...\"\n",
    "\n",
    "NV_INGEST_URL=\"...\"\n",
    "NV_RERANK_URL=\"...\"\n",
    "\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "\n",
    "```\n",
    "\n",
    "To-do for me is to remove the reranker as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from arize.otel import register\n",
    "from dotenv import load_dotenv\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "from src.python.generate_queries import generate_questions_from_files\n",
    "from src.python.RagRetriever import RAGRetriever\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "tracer_provider = register(\n",
    "    space_id = os.getenv(\"ARIZE_SPACE_ID\"),\n",
    "    api_key =  os.getenv(\"ARIZE_API_KEY\"),\n",
    "    project_name = \"rag-app-notebook\",\n",
    ")\n",
    "LangChainInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "\n",
    "\n",
    "rag_retriever = RAGRetriever(\n",
    "    collection_name=\"chunk_size_500\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "\n",
    "\n",
    "pdf_dir = \"./data/arxiv_papers\"\n",
    "qa_output = \"./train_dataset.json\"\n",
    "\n",
    "\n",
    "if not os.path.exists(qa_output):\n",
    "    questions = generate_questions_from_files(pdf_dir, max_files=20)\n",
    "questions = list(EmbeddingQAFinetuneDataset.from_json(qa_output).queries.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Queries - Similarity Search + Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_query(rag_retriever, query: str, similarity_top_k: int = 20, rerank_top_n: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"Process a single query and record timing information.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = rag_retriever.similarity_search(query, similarity_top_k=similarity_top_k, rerank_top_n=rerank_top_n)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"time\": time_taken,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "def run_concurrent_queries(rag_retriever, queries: List[str], max_workers: int = 4, \n",
    "                         similarity_top_k: int = 20, rerank_top_n: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Run queries concurrently with a progress bar and return timing results.\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                process_query, \n",
    "                rag_retriever, \n",
    "                query, \n",
    "                similarity_top_k, \n",
    "                rerank_top_n\n",
    "            ) for query in queries\n",
    "        ]\n",
    "        \n",
    "        for future in tqdm(\n",
    "            concurrent.futures.as_completed(futures),\n",
    "            total=len(futures),\n",
    "            desc=\"Processing queries\",\n",
    "            unit=\"query\"\n",
    "        ):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                # Just log the error without interrupting the progress bar\n",
    "                all_results.append({\"time\": None, \"error\": str(e)})\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def calculate_percentiles(times: List[float]) -> Dict[str, float]:\n",
    "    \"\"\"Calculate various percentiles of the timing data.\"\"\"\n",
    "    percentiles = {\n",
    "        \"p50\": np.percentile(times, 50),\n",
    "        \"p75\": np.percentile(times, 75),\n",
    "        \"p90\": np.percentile(times, 90),\n",
    "        \"p95\": np.percentile(times, 95),\n",
    "        \"p99\": np.percentile(times, 99),\n",
    "    }\n",
    "    return percentiles\n",
    "\n",
    "max_workers = 4\n",
    "\n",
    "results = run_concurrent_queries(\n",
    "    rag_retriever, \n",
    "    questions, \n",
    "    max_workers=max_workers,\n",
    "    similarity_top_k=20, \n",
    "    rerank_top_n=3\n",
    ")\n",
    "\n",
    "query_times = [result[\"time\"] for result in results if result[\"time\"] is not None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics - Similarity Search + Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Latency Statistics:\n",
      "----------------------------------------\n",
      "Average: 0.3605s\n",
      "Minimum: 0.1799s\n",
      "Maximum: 5.3893s\n",
      "\n",
      "Percentile Latencies:\n",
      "p50 (median): 0.3105s\n",
      "p75: 0.3661s\n",
      "p90: 0.4742s\n",
      "p95: 0.5469s\n",
      "p99: 1.2784s\n",
      "\n",
      "Standard deviation: 0.3368s\n",
      "\n",
      "Total queries: 522\n",
      "Failed queries: 0\n",
      "\n",
      "Total sequential processing time: 188.1807s\n",
      "Wall clock time with concurrency: 5.3893s\n",
      "Speedup from concurrency: 34.92x\n"
     ]
    }
   ],
   "source": [
    "if query_times:\n",
    "    avg_time = statistics.mean(query_times)\n",
    "    min_time = min(query_times)\n",
    "    max_time = max(query_times)\n",
    "    \n",
    "    percentiles = calculate_percentiles(query_times)\n",
    "    \n",
    "    print(\"\\nQuery Latency Statistics:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Average: {avg_time:.4f}s\")\n",
    "    print(f\"Minimum: {min_time:.4f}s\")\n",
    "    print(f\"Maximum: {max_time:.4f}s\")\n",
    "    \n",
    "    print(\"\\nPercentile Latencies:\")\n",
    "    print(f\"p50 (median): {percentiles['p50']:.4f}s\")\n",
    "    print(f\"p75: {percentiles['p75']:.4f}s\")\n",
    "    print(f\"p90: {percentiles['p90']:.4f}s\")\n",
    "    print(f\"p95: {percentiles['p95']:.4f}s\")\n",
    "    print(f\"p99: {percentiles['p99']:.4f}s\")\n",
    "    \n",
    "    if len(query_times) > 1:\n",
    "        stddev = statistics.stdev(query_times)\n",
    "        print(f\"\\nStandard deviation: {stddev:.4f}s\")\n",
    "    \n",
    "    print(f\"\\nTotal queries: {len(query_times)}\")\n",
    "    print(f\"Failed queries: {len(results) - len(query_times)}\")\n",
    "    \n",
    "    total_sequential_time = sum(query_times)\n",
    "    elapsed_wall_time = max(result[\"time\"] for result in results if result[\"time\"] is not None)\n",
    "    \n",
    "    print(f\"\\nTotal sequential processing time: {total_sequential_time:.4f}s\")\n",
    "    print(f\"Wall clock time with concurrency: {elapsed_wall_time:.4f}s\")\n",
    "    print(f\"Speedup from concurrency: {total_sequential_time / elapsed_wall_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Queries - Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_query(rag_retriever, query: str, similarity_top_k: int = 20, rerank_top_n: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"Process a single query and record timing information.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = rag_retriever.get_relevant_documents(query)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"time\": time_taken,\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "def run_concurrent_queries(rag_retriever, queries: List[str], max_workers: int = 4, \n",
    "                         similarity_top_k: int = 20, rerank_top_n: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Run queries concurrently with a progress bar and return timing results.\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                process_query, \n",
    "                rag_retriever, \n",
    "                query, \n",
    "                similarity_top_k, \n",
    "                rerank_top_n\n",
    "            ) for query in queries\n",
    "        ]\n",
    "        \n",
    "        for future in tqdm(\n",
    "            concurrent.futures.as_completed(futures),\n",
    "            total=len(futures),\n",
    "            desc=\"Processing queries\",\n",
    "            unit=\"query\"\n",
    "        ):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                # Just log the error without interrupting the progress bar\n",
    "                all_results.append({\"time\": None, \"error\": str(e)})\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def calculate_percentiles(times: List[float]) -> Dict[str, float]:\n",
    "    \"\"\"Calculate various percentiles of the timing data.\"\"\"\n",
    "    percentiles = {\n",
    "        \"p50\": np.percentile(times, 50),\n",
    "        \"p75\": np.percentile(times, 75),\n",
    "        \"p90\": np.percentile(times, 90),\n",
    "        \"p95\": np.percentile(times, 95),\n",
    "        \"p99\": np.percentile(times, 99),\n",
    "    }\n",
    "    return percentiles\n",
    "\n",
    "max_workers = 4\n",
    "\n",
    "results = run_concurrent_queries(\n",
    "    rag_retriever, \n",
    "    questions, \n",
    "    max_workers=max_workers,\n",
    "    similarity_top_k=20, \n",
    "    rerank_top_n=3\n",
    ")\n",
    "\n",
    "query_times = [result[\"time\"] for result in results if result[\"time\"] is not None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics - Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Latency Statistics:\n",
      "----------------------------------------\n",
      "Average: 0.3887s\n",
      "Minimum: 0.1860s\n",
      "Maximum: 5.4589s\n",
      "\n",
      "Percentile Latencies:\n",
      "p50 (median): 0.3249s\n",
      "p75: 0.3939s\n",
      "p90: 0.5143s\n",
      "p95: 0.5761s\n",
      "p99: 1.9352s\n",
      "\n",
      "Standard deviation: 0.3530s\n",
      "\n",
      "Total queries: 522\n",
      "Failed queries: 0\n",
      "\n",
      "Total sequential processing time: 202.9216s\n",
      "Wall clock time with concurrency: 5.4589s\n",
      "Speedup from concurrency: 37.17x\n"
     ]
    }
   ],
   "source": [
    "if query_times:\n",
    "    avg_time = statistics.mean(query_times)\n",
    "    min_time = min(query_times)\n",
    "    max_time = max(query_times)\n",
    "    \n",
    "    percentiles = calculate_percentiles(query_times)\n",
    "    \n",
    "    print(\"\\nQuery Latency Statistics:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Average: {avg_time:.4f}s\")\n",
    "    print(f\"Minimum: {min_time:.4f}s\")\n",
    "    print(f\"Maximum: {max_time:.4f}s\")\n",
    "    \n",
    "    print(\"\\nPercentile Latencies:\")\n",
    "    print(f\"p50 (median): {percentiles['p50']:.4f}s\")\n",
    "    print(f\"p75: {percentiles['p75']:.4f}s\")\n",
    "    print(f\"p90: {percentiles['p90']:.4f}s\")\n",
    "    print(f\"p95: {percentiles['p95']:.4f}s\")\n",
    "    print(f\"p99: {percentiles['p99']:.4f}s\")\n",
    "    \n",
    "    if len(query_times) > 1:\n",
    "        stddev = statistics.stdev(query_times)\n",
    "        print(f\"\\nStandard deviation: {stddev:.4f}s\")\n",
    "    \n",
    "    print(f\"\\nTotal queries: {len(query_times)}\")\n",
    "    print(f\"Failed queries: {len(results) - len(query_times)}\")\n",
    "    \n",
    "    total_sequential_time = sum(query_times)\n",
    "    elapsed_wall_time = max(result[\"time\"] for result in results if result[\"time\"] is not None)\n",
    "    \n",
    "    print(f\"\\nTotal sequential processing time: {total_sequential_time:.4f}s\")\n",
    "    print(f\"Wall clock time with concurrency: {elapsed_wall_time:.4f}s\")\n",
    "    print(f\"Speedup from concurrency: {total_sequential_time / elapsed_wall_time:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pepsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
